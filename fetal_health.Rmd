---
title: "Fetal Health"
author: "Finn de Lange"
date: "2025-05-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE
)

```

**Data import**

```{r}
data <- read_csv("fetal_health.csv")

for (col_name in names(data)) {
  if (is.numeric(data[[col_name]])) {
    hist(data[[col_name]], 
         main = paste("Histogram of", col_name), 
         xlab = col_name, 
         col = "skyblue", 
         border = "white")
  } else {
    print(paste(col_name, "is not numeric and was skipped."))
  }
}
```

It is fairly clear that many of these variables do not follow multivariate normality. We can further test this using a Mardia test.

```{r}
library(MVN)
mvn(data = data, mvnTest = "mardia")[2]
```

Based on these outputs, we can clearly see that our data is not multivariate normal.

**Basic summary statistics**

```{r}
data %>%
  summary()
```

**Investigating correlations**

```{r}
library(reshape2)
library(RColorBrewer)

df_numeric <- as.data.frame(lapply(data, as.numeric))

# Compute correlation matrix
cor_matrix <- cor(df_numeric, use = "pairwise.complete.obs")

# Melt the correlation matrix to long format
cor_melted <- melt(cor_matrix)

# Create heatmap
ggplot(cor_melted, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "black") +
  scale_fill_gradient2(
    low = "black", mid = "skyblue", high = "white",
    midpoint = 0.5, limit = c(-0.5, 1),
    name = "Correlation"
  )


```

There do not appear to be any particularly stand out values that correlate, aside from summary statistics (mean, median and mode of the histogram correlate highly).

Given that the fetal health column is recorded and can tell us if the infant was classified as normal, suspect or pathological, we should be able to create model that can classify into two groups - normal or of concern.

We can first create a new column by collapsing the suspect and pathological groups into a single group, and re-code the system to use 0 for normal and 1 for of concern.

```{r}
data <- data %>%
  mutate(
    recoded = ifelse(fetal_health == 1, 0, 1)
  ) %>%
  dplyr::select(-fetal_health)

plot_data <- data
colnames(plot_data) <- paste0(seq_along(data))

cor_matrix <- cor(plot_data[, 1:21], use = "complete.obs")
cor_matrix[abs(cor_matrix) < 0.7] <- NA 
round(cor_matrix, 2)

colnames(data[,c(12, 13, 15)])
```

**Rudimentary model fitting**

From the variance inflation factor analysis above, we can see that there are a few variables that correlate very highly. In particular, we can see that 3x3 block in the lower right of the matrix. These are the mode, mean and median of the histogram, so a high level of multicolinearity is expected. Similarly, the other variables in high association with each other are histogram width, minimum and number of peaks, which we also expect. 

For now, we shall leave these terms in our data. Since we are using principal components analysis, the resultant components constructed are orthogonal.

```{r}
dimension_reduced <- prcomp(data[,1:21], scale = TRUE, center = TRUE)

screeplot(dimension_reduced)

sum(dimension_reduced$sdev[1:5]^2)/sum(dimension_reduced$sdev^2)

round(dimension_reduced$sdev^2 / sum(dimension_reduced$sdev^2), 2)
```

Based on the screeplot and proportion of variance explained, using four of five principal components seems to be a viable option. Given this, we can now begin trying to fit a logistic model.

Let us now consider if we can find any meaningful separation using the principal components.

```{r}
colours <- ifelse(data$recoded == 1, 'red', 'blue')
pairs(dimension_reduced$x[,1:5], col=colours)
```

Based on the plot, we can see that there is significant overlap in many of the principal component pairings, However, there do appear to be a few pairings when there is better separtion than others, such as all of the PC3 groupings. Additionally, all of the PC5 groupings show a smaller cluster that appears to be a mix of normal and of concern infants. This may be worth further investigation at another time, but unfortunately does not aim in solving our problem.

In our next step we will attempt to fit the logistic model, which will involve dredging over all the possible combinations. I have chosen to use AICc as my dredging criteria. We will first consider if any of our derived variables require transformation.

```{r}
library(mgcv)

derived_data <- as.data.frame(dimension_reduced$x[,1:5])
derived_data$code <- data$recoded

gam.fit <- gam(code ~ s(PC1) + s(PC2) + s(PC3) + s(PC4) + s(PC5), family = "binomial", data = derived_data)

plot(gam.fit)
```

It does not appear like our data requires any transformations. Now we can move on to dredging our model. I intend to avoid any interaction terms with more than two variables, as it makes interpretation of the model more difficult.

```{r}
library(MuMIn)

anova(glm(code ~  PC1 * PC2 * PC3 * PC4 * PC5, data = derived_data, family = binomial), test='Chisq')

full_model <- glm(code ~ PC1 * PC2 + PC1 * PC3 + PC2 * PC3 + PC1 * PC4 + PC1 * PC5 + PC2 * PC5 + PC4 * PC5, data = derived_data, family = binomial)

options(na.action = "na.fail")

dredged_model <- dredge(full_model)

chosen_model <- get.models(dredged_model, 2)[[1]]

summary(chosen_model)
```

I ended up choosing the second model provided by dredge, as it had a comparable AICc to the first model, but the first model also included a non-significant interaction term while the second model does not.

```{r}
deviance <- deviance(chosen_model)
df <- df.residual(chosen_model)

# p-value for goodness-of-fit test
1 - pchisq(deviance, df)
```

Since we are using principal components, this goodness-of-fit test does not tell us much.

```{r}
boxplot(fitted(chosen_model) ~ derived_data$code,
        main = "Fitted probabilities by outcome",
        xlab = "Actual code", ylab = "Predicted probability")

library(statmod)
plot(fitted(chosen_model), qresiduals(chosen_model))
```

Based on the outputs here, we can see that our residuals are mostly random noise with one outlier, and that there is a clear separation between the groups or normal and of concern infants.

Lastly, let us consider our cross-validation to determine how well our model can predict the health of the infants.

```{r}
library(crossval)

predfun.lm <- function(train.x, train.y, test.x, test.y) {
  glm.fit <- glm(train.y ~ ., data = train.x, family = binomial)
  ynew <- predict(glm.fit, test.x, type = 'response')
  mean((ynew - test.y))^2
}

y.fit1 <- "code"
cv.out = crossval(predfun.lm, X = derived_data[,c('PC1', 'PC2', 'PC3', 'PC4', 'PC5')], Y = derived_data[, y.fit1], K = 10, B = 1, verbose = FALSE)
MSPE_1 <- cv.out$stat
MSPE_1se <- cv.out$stat.se

MSPE_1
MSPE_1se
```

So our model fits extremely well. To put our derived variables back into a more interpretable form, let us consider what each principal component may be representing, but investigating their loadings. It is especially of interest to see the loadings of PC3 as it has the greatest estimated coefficient.

```{r}
dimension_reduced$rotation[, 1:5]%*%diag(dimension_reduced$sd[1:5]) -> new_scale
class(new_scale)<-"loadings"
new_scale
```

**PC1**
- Possibly represents overall fetal heart rate level and distribution. Higher scores tend to correlate with lower variation, fewer decelerations, and higher histogram averages (mean, media, mode.
- Could benefit from being mirrored from interpretability.
- Loads lowly on mean value of long term variability, *only*.

**PC2**
- Appears to focus more on histogram shape and overall heart rate dispersion, loading very low on the histogram averages that PC1 loaded highly on.
- Could be used as a constrast to PC1.

**PC3**
- Loads highest on variabilities and movements.
- Does not have any especially large loadings.

**PC4**
- Loads highest on accelerations, histogram tendency and variability.
- Does not load highly on decelerations at all.
- Hardly loads on the histogram values.

**PC5**
- Loads very highly on fetal movement, followed by uterine contractions, although the latter is negatively loaded.
- Loads against most decelerations except for prolongued decelerations.
- Barely loads on any summary statistics, with almost none of the average/max/min/variability variables being loaded on.

Overall it is very difficult to definitively claim what any of these derived variables represent, especially given my limited knowledge of neo-natal care, and cardiology. However, what is clear from this analysis is that we can accurately classify children into of concern and healthy groupings, which may prove beneficial to health professionals. That said, there is a significant issue in the fact that the mathemtaics used to get to this conclusion has arrived at a fairly complex model based on derived components. Because of this, the it is not simple equation nor rule of thumb that a practitioner may use, and would in all likelihood require a computer with the model pre-loaded, and then require the inputting of all measurements, significantly delaying the process. 

However, one useful piece of information revealed in this analysis is that the baseline value is important in the loadings of the first three principal components, accounting for much of the variation, but also that many of the histogram averages are only loaded by the first two prinicpal components, in opposit directions. This suggests that a less complicated model should be possible, perhaps based on this variables, but likely requiring more as well.



***Next steps***

- Logging some of the variables
- Removing some of the variables
- Using an ROC
